---
title: "Python Headaches"
subtitle: "Sprint 2 Wk2"
layout: post
img: "/img/circuit2.jpg"
---

Previously, my device had a photo-resistor connected which would read the incoming light levels over the Blynk app. In order to improve the accuracy of my device, I would need a more accurate device to detect light and give readings. Therefore, I installed in a BH1750 light sensor module in order to more accurately displays levels of light. With some easy wiring, I now had to get code in order for it to display without using Blynk. Luckily, the libraries on PlatformIO are bountiful and as such, it enabled me to be able to find one specifically for the BH1750. Now, I was able to get the reading from the sensor to show up on the serial monitor within visual studio code. However, when I was doing some rudimentary testing for how I originally planned for my device to work, I discovered an issue. Just simply using a LED to shine upon the object and then detect it with just one sensor would not be enough. Also, with all those readings, the data would plot out to a simple line graph just measuring lux. I decided to do more research to be able to improve my device.

![Circuit Revised](/img/circuit2.jpg)

Also in this sprint, each team had to set up a framework for communication. In our team, we were each picked out parts of the framework to work on. From what I understand, IoT devices need to be able to connect wirelessly to networks and have the ability to transmit data. These devices are then able to communicate over internet and be remotely monitored or controlled. This diagram courtesy of Sebastian, is a great illustration of the framework that is in place.

My focus in this framework was on data visualization. The reason why data visualization is important is because it is much easier to spot patterns that can potentially emerge. Initially, Metabase was offered as an easy option in order to view data. The installation was very simple and I set up a Metabase platform on my local host and played around with the sample data-sets provided. While Metabase is easy to use, I wanted to explore if there were other options that could allow me to be more flexible and more importantly, allow live-streaming of data. Since it coincided with one of my learning objectives anyway, I decided to spend most of my time devoted to learning the python stack for data analysis. This stack includes libraries such as:
- NumPy
- Pandas
- Matplotlib

I also trialed with Plotly, another data plotting library and more specifically, using their data visualization platform Dash. Now if you’re like me, you probably have never heard of these libraries before, so naturally I needed a tutorial to help me figure it out. A quick google search and this tutorial by CS Dojo popped out [![Intro CS Dojo](http://img.youtube.com/vi/a9UrKTVEeZA/0.jpg)](http://www.youtube.com/watch?v=a9UrKTVEeZA). Through this, I was able to install the libraries through the anaconda cloud package and also at the same time Jupyter Notebook. Jupyter Notebook is a really simple way be able to visualize the output and share code.

Here is my first graph.
![First Graph](/img/graph1.png)

Next, I choose the follow along with this guide and understand more about the stack. After this I gained a greater understanding of the libraries in python. NumPy is a library that sorts everything into arrays of numbers. In essence, everything is an array of numbers – where pictures are simply 2-D arrays of numbers representing pixel brightness of an area or sound being an array of intensity vs time. Since this means that data analysis can only occur when everything is converted into numbers, the NumPy package is an efficient interface for operating and storing data. This is considered the building block of python data analysis. Building on NumPy, comes Pandas. Pandas has 3 main objects and in my case, I focused on the object DataFrame. This allows me to be able to import data and convert it into a Python object with rows and columns. Finally, MatPlotLib is a data visualization library that allows graphing in Python. Now all I need to learn was how to plot live data ![Live-Graph](http://img.youtube.com/vi/ZmYPzESC5YY/0.jpg)](http://www.youtube.com/watch?v=ZmYPzESC5YY), and now I would try visualize my light sensor readings. Early on, I discovered that I would have great difficulty in allowing other people to access the visual graphics from MatPlotLib. This is not to say it is impossible, but I had no experience with JavaScript and that would be the only way I know of to be able to accomplish this task. This is where Dash came in. Dash is a python framework that allows you to build web applications for analytics without the use of JavaScript. Following tutorials from sentdex [![Dash Example](http://img.youtube.com/vi/luixWRpp 6Jo/0.jpg)](http://www.youtube.com/watch?v=luixWRpp 6Jo) I was able to plot graphs onto a web page and also able to refresh a page to get live-increments, however, not able to do both at the same time. This is because, the code provided from sentdex included an Event object. As of February this year, this object was removed and thus I had to tweak the code. I was unsuccessful in making the combination of live data work.

Undeterred, I chose to try from MongoDB static. Since Pandas is able to export data from MongoDB, I decided to try to first get the data and then graph it naturally. However, I was not able to export the data from the database into the Pandas DataFrame object running into multiple errors along the way. Eventually, I had to use Metabase’s export option in order to download a CSV file that I was able to translate into a Pandas DataFrame and in turn a graph.

![Light Sensor](/img/lightsensor.png)

Now why did I go through the trouble of learning about this Python stack. This is because for my device, I need to use a lot of data analysis in order to get the wavelengths of each object. The plan now is to try to either use or create a spectrometer to identify the materials. Then, by plotting each objects wavelength with respect to absorption of light, I will be able to see the peak wavelengths and if the peak wavelengths do not coincide, then I will be able to have a way of filtering out which objects are what.   


