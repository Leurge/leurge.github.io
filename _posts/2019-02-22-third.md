---
title: "Spectroscopy"
subtitle: "Sprint 3 Wk3"
layout: post
image: "/img/nir.jpg"
---

For this sprint the focus is on improving the prototype. My current prototype consists of a light sensor and an LED. It operates based on an LED flashing light that is reflected of the object and picked up by the light sensor, which collects the emitted light level and through that differentiate the  material. However, the problem with this is that the light sensor is only detecting the brightness of light and not each individual spectrum or wavelength. The reason this is important is because objects, especially plastic, absorb wavelengths of light in the infrared region specifically and thus I would need to upgrade my sensor to enable detection of those wavelengths. Essentially, I discovered that I was trying to design an instrument called a spectrometer. The basic principal behind it is that the object is shone with a light and then the reflected light is focused to a sensor which gives a reading. Then, using an equation A = log(1/R) where A is absorbance and R is the amount of recorded reflection, this will be able to produce an estimate of the amount that the material absorbed and hopefully be able to give a profile of each material. 

The first problem would be the creation of the device. Most spectrometers on the market use a complex configuration known as the Czerny-Turner Configuration. 

![Layout](/img/diagram.jpeg)

As seen above, the light enters and is focused through the first mirror and sent to the second mirror which contains a diffraction grating. This splits up the light further into different wavelengths and reflects off the final mirror before heading to a reader. Most spectrometers use linear image readers which essential are like mini-cameras in order to read the data. This configuration would be very difficult for me to reproduce and in order to procure a linear-image sensor would also be very difficult. After a bit of Google searching, I discovered a Near Infrared (NIR) sensor made by Sparkfun.

![NIR Sensor](/img/nir.jpg)

NIR refers to a specific wavelength within the infrared spectrum which is between 780nm to 2500nm, i.e. wavelength closest to visible light. My sensor however, detects in ranges from 610nm – 860nm. The sensor can also measure temperature but this reading will not be used for my purposes. This means when testing materials, the reading would not be the most accurate as the more bands detected, the more comprehensive a picture can be graphed. The sensor comes with its own library which can be implemented easily. 

![Readings](/img/reading.png)

The readings are represented by letters which correspond to the wavelengths they detect:
|  |  |  |
|  -  |  -  |  -  |
|R = 610nm |U = 760nm |          
|S = 680nm |V = 810nm |
|T = 730nm |W = 860nm |
each with a ± of 20nm. The board also includes an LED which can be used to illuminate the object and record the reflected light. There is an issue with the LED which is that the white light emitted is not uniform in the intensity across the spectrum. It is possible that I may need to buy a halogen lamp in order to get a better reading. However, the real problem is on the software side of things. Off the back of my python boot-camp last sprint, I proceeded to try to generate a graph from the readings off the sensor. I was unable to do so and it will be my mission in the next sprint. 

During the time it took for the part to be delivered, I decided to try to learn more about Node.js. In order to accomplish this and further one of my learning objectives, I decided to complete the beginner book on Node by Manuel Kiessling, which was provided by Danon. In this book, I was able to host my own server and manipulate it to eventually allow for image uploading. I also have begun upon the second book which is much more complete than the beginner book and goes into more detail about Node functions. The reason why I am learning it is because, ideally, users are able to access a web-page that will allow them to submit products that are recyclable and the associated wavelength image. This will then be checked and submitted into a database while at the same time allowing every device to be able to detect this new product as recyclable. That way, the sensor becomes more accurate as it grows through its constantly expanding library through the help of the users. This will also be another mission for the last sprint. 

Finally, the last sprint will require me to think of an enclosure for this device to maximise the amount of light reflected and be practical for use.
